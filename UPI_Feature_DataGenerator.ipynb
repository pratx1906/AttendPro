{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNx7PCtyF99axwDQ9Ukq04I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Fraud Dataset Generator Engine (UPI Payments Simulation)\n",
        "# ==========================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "import networkx as nx\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Adjustable params\n",
        "TARGET_ROWS = 8000          # desired final dataset size\n",
        "BASE_CSV = \"/content/upi_features.csv\"  # path in Colab\n",
        "OUT_CSV = \"upi_synthetic_enhanced.csv\"\n",
        "BASE_LABEL_NOISE = 0.01     # fraction of labels to flip\n",
        "FRAUD_BASE_RATE = 0.02      # baseline fraud prevalence\n",
        "INJECT_ARC_INTENSITY = 1.2  # controls injected archetypes\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def make_uuid():\n",
        "    return str(uuid.uuid4())\n",
        "\n",
        "def rand_ip(rng=np.random):\n",
        "    return \".\".join(str(rng.randint(1, 255)) for _ in range(4))\n",
        "\n",
        "def rand_timestamp(start, end, rng=np.random):\n",
        "    s = int((end - start).total_seconds())\n",
        "    return start + timedelta(seconds=int(rng.randint(0, s)))\n",
        "\n",
        "def make_upi_id(prefix: str, rng=np.random):\n",
        "    return f\"{prefix}{rng.randint(10_000, 99_999_999)}@upi\"\n",
        "\n",
        "def jitter_numeric(x, scale=0.01, rng=np.random):\n",
        "    return float(np.round(x * (1 + rng.normal(0, scale)) +\n",
        "                          rng.normal(0, scale * abs(x)), 6))\n",
        "\n",
        "def sample_with_replacement(df, n):\n",
        "    idx = np.random.choice(df.index, size=n, replace=True)\n",
        "    return df.loc[idx].reset_index(drop=True)\n",
        "\n",
        "def mutate_upi(value, rng=np.random, prefix=\"user\"):\n",
        "    if isinstance(value, str) and \"@\" in value:\n",
        "        return make_upi_id(prefix, rng)\n",
        "    else:\n",
        "        return make_upi_id(prefix, rng)\n",
        "\n",
        "def safe_mutate_merchant(v, rng):\n",
        "    if pd.isna(v) or not isinstance(v, str) or v.strip() == \"\":\n",
        "        return mutate_upi(\"\", rng, prefix=\"merchant\")\n",
        "    if rng.rand() < 0.4:\n",
        "        return mutate_upi(v.replace(\"@upi\", \"\"), rng, prefix=\"merchant\")\n",
        "    return v\n",
        "\n",
        "# -----------------------------\n",
        "# Load seed dataset\n",
        "# -----------------------------\n",
        "def load_seed(path):\n",
        "    df = pd.read_csv(path)\n",
        "    try:\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "    except Exception:\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\").fillna(pd.Timestamp.now())\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Augment seed\n",
        "# -----------------------------\n",
        "def augment_seed(df_seed, target_n, rng=np.random):\n",
        "    seed_n = len(df_seed)\n",
        "    if seed_n >= target_n:\n",
        "        df = df_seed.sample(n=target_n, random_state=SEED).reset_index(drop=True)\n",
        "    else:\n",
        "        df = sample_with_replacement(df_seed, n=target_n)\n",
        "\n",
        "    # jitter numeric cols\n",
        "    for col in [\"amount\",\"balance_before\",\"balance_after\",\n",
        "                \"dest_balance_before\",\"dest_balance_after\",\n",
        "                \"merchant_risk_score\",\"risk_score\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda v: jitter_numeric(max(0.0, float(v)), scale=0.2, rng=rng))\n",
        "\n",
        "    # mutate ids\n",
        "    df[\"payer_id\"] = df[\"payer_id\"].apply(lambda v: mutate_upi(v, rng) if rng.rand()<0.35 else v)\n",
        "    df[\"payee_id\"] = df[\"payee_id\"].apply(lambda v: mutate_upi(v, rng) if rng.rand()<0.4 else v)\n",
        "    df[\"merchant_id\"] = df[\"merchant_id\"].apply(lambda v: safe_mutate_merchant(v, rng))\n",
        "    df[\"device_id\"] = df[\"device_id\"].apply(lambda v: make_uuid() if rng.rand()<0.25 else v)\n",
        "    df[\"ip_address\"] = df[\"ip_address\"].apply(lambda v: rand_ip(rng) if rng.rand()<0.3 else v)\n",
        "\n",
        "    # jitter booleans\n",
        "    for b in [\"is_new_device\",\"kyc_verified\",\"is_weekend\",\n",
        "              \"is_large_txn\",\"is_night_txn\",\"is_device_shared\",\"is_ip_shared\"]:\n",
        "        if b in df.columns:\n",
        "            df[b] = df[b].apply(lambda v: int(bool(v)) if rng.rand()>0.03 else int(not bool(v)))\n",
        "\n",
        "    # jitter counts\n",
        "    for cnt in [\"num_prev_txns_24h\",\"num_prev_txns_7d\",\"num_users_per_device\",\n",
        "                \"num_users_per_ip\",\"device_age_days\",\"customer_tenure_days\",\n",
        "                \"settlement_time_seconds\"]:\n",
        "        if cnt in df.columns:\n",
        "            df[cnt] = df[cnt].apply(lambda v: max(0, int(abs(v + rng.normal(0, max(1,0.2*abs(v)+1))))))\n",
        "\n",
        "    # timestamps\n",
        "    min_ts, max_ts = df_seed[\"timestamp\"].min(), df_seed[\"timestamp\"].max()\n",
        "    df[\"timestamp\"] = df[\"timestamp\"].apply(lambda t: rand_timestamp(min_ts,max_ts,rng) if rng.rand()<0.5 else t)\n",
        "    df[\"txn_hour\"] = pd.to_datetime(df[\"timestamp\"]).dt.hour\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Fraud scoring\n",
        "# -----------------------------\n",
        "def assign_fraud_scores(df, rng=np.random, intensity=1.0):\n",
        "    def score_row(r):\n",
        "        s = 0.0\n",
        "        s += 2.0*r[\"merchant_risk_score\"] + 2.0*r[\"risk_score\"]\n",
        "        if r[\"balance_before\"]>0:\n",
        "            ratio = r[\"amount\"]/(r[\"balance_before\"]+1e-9)\n",
        "            if ratio>0.25: s += 1.0*(ratio-0.25)\n",
        "            if ratio>1.0: s += 2.0\n",
        "        if r[\"is_new_device\"] and r[\"customer_tenure_days\"]<60: s+=1.5\n",
        "        if r[\"num_prev_txns_24h\"]>=5: s += 1.0+0.2*(r[\"num_prev_txns_24h\"]-5)\n",
        "        if r[\"settlement_time_seconds\"]<3: s+=0.8\n",
        "        if r[\"settlement_time_seconds\"]>3600: s+=0.5\n",
        "        if r[\"txn_type\"]==\"P2P\": s+=0.2\n",
        "        if r[\"browser\"]==\"android_custom\": s+=0.4\n",
        "        if r.get(\"is_night_txn\",False): s+=0.2\n",
        "        if r.get(\"is_device_shared\",False): s+=0.7\n",
        "        if r.get(\"is_ip_shared\",False): s+=0.5\n",
        "        s += rng.normal(0,0.5)\n",
        "        return max(0.0,s)*float(intensity)\n",
        "    df[\"fraud_score_raw\"]=df.apply(score_row,axis=1)\n",
        "    df[\"fraud_score_prob\"]=1.0/(1.0+np.exp(-(df[\"fraud_score_raw\"]-2.0)))\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Feature expansion\n",
        "# -----------------------------\n",
        "def expand_features(df, rng=np.random):\n",
        "    df[\"timestamp\"]=pd.to_datetime(df[\"timestamp\"])\n",
        "    df[\"txn_day\"]=df[\"timestamp\"].dt.day\n",
        "    df[\"txn_week\"]=df[\"timestamp\"].dt.isocalendar().week.astype(int)\n",
        "    df[\"txn_month\"]=df[\"timestamp\"].dt.month\n",
        "    df[\"txn_minute\"]=df[\"timestamp\"].dt.minute\n",
        "    df[\"hour_bucket\"]=pd.cut(df[\"txn_hour\"],bins=[-1,6,12,18,23],\n",
        "                             labels=[\"night\",\"morning\",\"afternoon\",\"evening\"])\n",
        "\n",
        "    df[\"amount_log\"]=np.log1p(df[\"amount\"].clip(lower=0.01))\n",
        "    df[\"amount_to_balance\"]=(df[\"amount\"]/(df[\"balance_before\"]+1e-9)).round(6)\n",
        "    df[\"balance_change\"]=(df[\"balance_before\"]-df[\"balance_after\"]).round(6)\n",
        "\n",
        "    payer_grp=df.groupby(\"payer_id\")[\"amount\"]\n",
        "    df[\"payer_amount_mean\"]=df[\"payer_id\"].map(payer_grp.mean()).fillna(df[\"amount\"].mean())\n",
        "    df[\"payer_amount_std\"]=df[\"payer_id\"].map(payer_grp.std()).fillna(0.0)\n",
        "    df[\"payer_txn_count\"]=df.groupby(\"payer_id\")[\"amount\"].transform(\"count\")\n",
        "\n",
        "    if \"merchant_id\" in df.columns:\n",
        "        mer_grp=df.groupby(\"merchant_id\")[\"amount\"]\n",
        "        df[\"merchant_amount_mean\"]=df[\"merchant_id\"].map(mer_grp.mean()).fillna(df[\"amount\"].mean())\n",
        "        df[\"merchant_txn_count\"]=df.groupby(\"merchant_id\")[\"amount\"].transform(\"count\")\n",
        "        df[\"merchant_popularity_rank\"]=df[\"merchant_id\"].map(df[\"merchant_id\"].value_counts()).fillna(0)\n",
        "\n",
        "    df[\"distinct_devices_per_payer\"]=df.groupby(\"payer_id\")[\"device_id\"].transform(lambda x:x.nunique())\n",
        "    df[\"distinct_ips_per_payer\"]=df.groupby(\"payer_id\")[\"ip_address\"].transform(lambda x:x.nunique())\n",
        "    df[\"merchant_cat_variety\"]=df.groupby(\"payer_id\")[\"merchant_category\"].transform(lambda x:x.nunique())\n",
        "\n",
        "    df[\"amt_vs_payer_z\"]=(df[\"amount\"]-df[\"payer_amount_mean\"])/(df[\"payer_amount_std\"].replace(0,1)+1e-9)\n",
        "    amt_std=df[\"amount\"].std() if df[\"amount\"].std()>0 else 1.0\n",
        "    df[\"amt_vs_merchant_z\"]=(df[\"amount\"]-df[\"merchant_amount_mean\"].fillna(df[\"amount\"].mean()))/(amt_std+1e-9)\n",
        "\n",
        "    try:\n",
        "        g=nx.DiGraph()\n",
        "        edges=df[[\"payer_id\",\"payee_id\",\"amount\"]].dropna()\n",
        "        edges_sample=edges.sample(n=min(len(edges),4000),random_state=SEED)\n",
        "        for _,e in edges_sample.iterrows():\n",
        "            g.add_edge(str(e[\"payer_id\"]),str(e[\"payee_id\"]),weight=float(e[\"amount\"]))\n",
        "        pr=nx.pagerank(g,alpha=0.85)\n",
        "        df[\"payer_pagerank\"]=df[\"payer_id\"].map(lambda x:pr.get(str(x),0.0))\n",
        "        df[\"payee_pagerank\"]=df[\"payee_id\"].map(lambda x:pr.get(str(x),0.0))\n",
        "        df[\"payer_degree\"]=df[\"payer_id\"].map(lambda x:g.degree(str(x)) if g.has_node(str(x)) else 0)\n",
        "        df[\"payee_degree\"]=df[\"payee_id\"].map(lambda x:g.degree(str(x)) if g.has_node(str(x)) else 0)\n",
        "    except Exception:\n",
        "        df[\"payer_pagerank\"]=0.0\n",
        "        df[\"payee_pagerank\"]=0.0\n",
        "        df[\"payer_degree\"]=0\n",
        "        df[\"payee_degree\"]=0\n",
        "\n",
        "    df[\"decoy_random_1\"]=np.random.randn(len(df))\n",
        "    df[\"decoy_random_2\"]=np.random.randint(0,50,size=len(df))\n",
        "    df[\"decoy_hash_mod\"]=df[\"payer_id\"].apply(lambda x:hash(str(x))%7)\n",
        "\n",
        "    # Safe fill\n",
        "    for c in df.select_dtypes(include=[\"category\",\"object\"]).columns:\n",
        "        df[c]=df[c].astype(str).replace(\"nan\",\"unknown\").fillna(\"unknown\")\n",
        "    for c in df.select_dtypes(include=[np.number]).columns:\n",
        "        df[c]=df[c].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Label finalization\n",
        "# -----------------------------\n",
        "def finalize_labels(df, base_rate=FRAUD_BASE_RATE, label_noise=BASE_LABEL_NOISE, rng=np.random):\n",
        "    eps=1e-9\n",
        "    combined=(0.6*df[\"fraud_score_prob\"].fillna(0)+\n",
        "              0.2*(df[\"amt_vs_payer_z\"].fillna(0).clip(-5,5)/5.0)+\n",
        "              0.1*df[\"payer_pagerank\"].fillna(0)+\n",
        "              0.2*df[\"is_device_shared\"].fillna(0)+\n",
        "              0.2*df.get(\"is_ip_shared\",0).fillna(0))\n",
        "    comb_min,comb_max=combined.min(),combined.max()\n",
        "    combined_norm=(combined-comb_min)/(comb_max-comb_min+eps)\n",
        "    final_prob=0.85*combined_norm+0.15*base_rate\n",
        "    df[\"isFraud_gen\"]=final_prob.apply(lambda p:int(rng.rand()<p))\n",
        "    df[\"isFraud\"]=df[\"isFraud_gen\"]\n",
        "\n",
        "    cur=df[\"isFraud\"].mean()\n",
        "    if cur<base_rate*0.6:\n",
        "        need=int((base_rate-cur)*len(df))\n",
        "        if need>0:\n",
        "            flip_idx=rng.choice(df.index,size=max(1,need),replace=False)\n",
        "            df.loc[flip_idx,\"isFraud\"]=1\n",
        "\n",
        "    df[\"isFlaggedFraud\"]=((df[\"fraud_score_prob\"]>0.6)|\n",
        "                          (df[\"merchant_risk_score\"]>0.85)|\n",
        "                          ((df[\"is_new_device\"]==1)&\n",
        "                           (df[\"amount\"]>df[\"payer_amount_mean\"]*5))).astype(int)\n",
        "\n",
        "    if label_noise>0:\n",
        "        flip_n=int(label_noise*len(df))\n",
        "        flip_idx=rng.choice(df.index,size=flip_n,replace=False)\n",
        "        df.loc[flip_idx,\"isFraud\"]=1-df.loc[flip_idx,\"isFraud\"]\n",
        "\n",
        "    df[\"label\"]=df.apply(lambda r:\"fraud\" if r[\"isFraud\"]==1 else \"legit\",axis=1)\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Final cleanup\n",
        "# -----------------------------\n",
        "def finalize_dataframe(df):\n",
        "    bool_cols=[\"is_new_device\",\"is_weekend\",\"is_large_txn\",\n",
        "               \"is_night_txn\",\"is_device_shared\",\"is_ip_shared\",\n",
        "               \"kyc_verified\",\"isFraud\",\"isFlaggedFraud\"]\n",
        "    for c in bool_cols:\n",
        "        if c in df.columns:\n",
        "            df[c]=df[c].replace({True:1,False:0,\"TRUE\":1,\"True\":1,\"true\":1,\n",
        "                                 \"FALSE\":0,\"False\":0,\"false\":0}).fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# Main pipeline\n",
        "# -----------------------------\n",
        "def generate_from_seed(base_csv=BASE_CSV,target_rows=TARGET_ROWS,\n",
        "                       label_noise=BASE_LABEL_NOISE,fraud_base_rate=FRAUD_BASE_RATE,\n",
        "                       inject_intensity=INJECT_ARC_INTENSITY,out_path=OUT_CSV,seed=SEED):\n",
        "    rng=np.random.RandomState(seed)\n",
        "    df_seed=load_seed(base_csv)\n",
        "    print(\"Seed rows:\",len(df_seed))\n",
        "\n",
        "    if target_rows<len(df_seed):\n",
        "        target_rows=len(df_seed)\n",
        "\n",
        "    df_aug=augment_seed(df_seed,target_rows,rng)\n",
        "    print(\"After augmentation rows:\",len(df_aug))\n",
        "\n",
        "    df_scored=assign_fraud_scores(df_aug,rng,intensity=inject_intensity)\n",
        "    df_expanded=expand_features(df_scored,rng)\n",
        "    df_labeled=finalize_labels(df_expanded,base_rate=fraud_base_rate,label_noise=label_noise,rng=rng)\n",
        "    df_final=finalize_dataframe(df_labeled)\n",
        "\n",
        "    if len(df_final)>target_rows:\n",
        "        df_final=df_final.sample(n=target_rows,random_state=seed).reset_index(drop=True)\n",
        "    elif len(df_final)<target_rows:\n",
        "        more=sample_with_replacement(df_final,target_rows-len(df_final))\n",
        "        df_final=pd.concat([df_final,more],ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "    df_final.to_csv(out_path,index=False)\n",
        "    print(\"Final rows:\",len(df_final))\n",
        "    print(\"Final fraud rate:\",df_final[\"isFraud\"].mean())\n",
        "    return df_final\n",
        "\n",
        "# -----------------------------\n",
        "# Run in Colab\n",
        "# -----------------------------\n",
        "if __name__==\"__main__\":\n",
        "    from google.colab import files\n",
        "    uploaded=files.upload()  # Upload your upi_features.csv\n",
        "    out=generate_from_seed(base_csv=BASE_CSV,target_rows=8000,\n",
        "                           label_noise=0.01,fraud_base_rate=0.02,\n",
        "                           inject_intensity=1.2,out_path=OUT_CSV,seed=SEED)\n",
        "    print(out.columns.tolist())\n",
        "    print(out[[\"isFraud\",\"label\"]].value_counts().head(20))\n",
        "    out[out[\"isFraud\"]==1].head(10)\n"
      ],
      "metadata": {
        "id": "YPsgBAEPj8ak",
        "outputId": "26c26957-9a04-417e-ad15-50dd67a3ce39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d8c51ccc-4f0e-46b3-a060-fd0ec50cc6ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d8c51ccc-4f0e-46b3-a060-fd0ec50cc6ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving upi_features.csv to upi_features (2).csv\n",
            "Seed rows: 2000\n",
            "After augmentation rows: 8000\n",
            "Final rows: 8000\n",
            "Final fraud rate: 0.328875\n",
            "['timestamp', 'txn_type', 'type', 'channel', 'status', 'payer_id', 'payee_id', 'merchant_id', 'merchant_category', 'merchant_risk_score', 'amount', 'balance_before', 'balance_after', 'dest_balance_before', 'dest_balance_after', 'device_id', 'device_age_days', 'is_new_device', 'ip_address', 'num_prev_txns_24h', 'num_prev_txns_7d', 'settlement_time_seconds', 'risk_score', 'isFraud', 'isFlaggedFraud', 'label', 'app_version', 'browser', 'customer_tenure_days', 'kyc_verified', 'notes', 'txn_hour', 'is_weekend', 'balance_drop_ratio', 'is_large_txn', 'is_night_txn', 'num_users_per_device', 'is_device_shared', 'num_users_per_ip', 'is_ip_shared', 'device_age_bucket', 'fraud_score_raw', 'fraud_score_prob', 'txn_day', 'txn_week', 'txn_month', 'txn_minute', 'hour_bucket', 'amount_log', 'amount_to_balance', 'balance_change', 'payer_amount_mean', 'payer_amount_std', 'payer_txn_count', 'merchant_amount_mean', 'merchant_txn_count', 'merchant_popularity_rank', 'distinct_devices_per_payer', 'distinct_ips_per_payer', 'merchant_cat_variety', 'amt_vs_payer_z', 'amt_vs_merchant_z', 'payer_pagerank', 'payee_pagerank', 'payer_degree', 'payee_degree', 'decoy_random_1', 'decoy_random_2', 'decoy_hash_mod', 'isFraud_gen']\n",
            "isFraud  label\n",
            "0        legit    5369\n",
            "1        fraud    2631\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}